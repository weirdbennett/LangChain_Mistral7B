# LangChain_Mistral7B
 Local data based Mistral 7B model

# Requirements:
 1. Install necessary libraries: pip install langchain langchain_community faiss-cpu huggingface_hub ollama
 2. Instal Mistral 7B model via Ollama
# Setup:
 1. Place your text file (data/data.txt) with the content you want to query.
 2. Run the script: python LocalMistral7B.py
# Usage:
 1. The program will prompt you to enter a question.
 2. Type your question, and the system will return an answer based on the loaded document.
 3. To exit, type exit.
