# LangChain_Mistral7B
 Local data based Mistral 7B model

# Requirements:
 Instal Mistral 7B model via Ollama
 Install necessary libraries: pip install langchain langchain_community faiss-cpu huggingface_hub ollama

# Setup:
 Place your text file (data/data.txt) with the content you want to query.
 Run the script: python LocalMistral7B.py

# Usage:
 1. The program will prompt you to enter a question.
 2. Type your question, and the system will return an answer based on the loaded document.
 3. To exit, type exit.
